# Stage 4: Creating a python algorithm that accepts varying data from CSVs

The motivation for this stage is to transition away from hardcoded scripts that only accept CSV files with a fixed structure, including specific column numbers and names. 

_Please note that I am still using CSVs because the data I currently have is stored in CSV format. The code takes these CSVs and converts them into a Python list. In the future, automated machines will only need to output a Python list with the necessary information for integration._

This code is designed with the following goals in mind:

1. **Data Input**: The script takes in data from the automated experiment as a Python list.
2. **Node and Relationship Generation**: It dynamically generates the appropriate nodes and relationships based on the type of operation.
3. **Flexible Node Properties**: Apart from a few required properties needed to identify and create nodes/relationships, the system allows node properties to be filled with any data.
4. **Real-Time Generation**: Nodes and relationships can be generated in real time or shortly after the experiment, without the need to re-upload the entire database.

## 4.1: Basic Structure of the Script

The [Jupyter Notebook](https://github.com/lteresah/AMLS-GraphDatabase/blob/main/Stage4/neo4jPythonAPI_DynamicCSV.ipynb) provided populates the database following these steps:

1. Reads in csv files from the internet and turns each into a pandas dataframe
2. Takes each pandas dataframe associated with an Operation Node, extracts the data from the able, and creates a chronologically ordered **Operation Log** which takes the form of a python list.

    The list has the following structure:
  
    | Operation Type (string) | Timestamp (datetime) | User (string) |  Operation ID (string) | Data (dict) |
    |:--------------:|:---------:|:----:|:-------------:|:----:|
    | 'Mix' |'2024-03-13T12:00:00'|'lteresa'| 'MIX-2024-03-13T12:00:00-lteresa:01-314024and01-334090at20C| {'Mix Timestamp': '2024-03-13T12:00:00',  'Executor': 'lteresa', 'Process Owner': 'dasb', 'Mix Operation ID': 'MIX-2024-03-13T12:00:00-lteresa:01-314024and01-334090at20C', 'Mix Temp (C)': 20, 'Dissolved': 'Y', 'New Object ID': '02-000001', 'New Object Type': 'Precursor', 'New Object Description': '1M CsCH3COO in HBr', ...}|
    | ... | ... | ... | ... | ... | 

3. Establishes connection to a Neo4j Database.
4. Performs a sophisticated process to create nodes and relationships in the database.

## 4.2: More Detailed Information on Node and Relationship Generation

### 4.2.1: Data Input

The script takes in two types of csv files:
1. Files associated with **objects** -- assumed to be independently maintained by some other system.
   - Example:
       - List of Users and User Information
       - List (Stock) of Ingredients and Ingredient Information
2. Files associated with **operations** -- manually recorded by a User or automatically outputed by an experiment

The files are originally read and stored as pandas dataframes. Operation Type files are collected and converted into a single python list (as described in the previous section), while Object Type files are eventually transformed into a dictionary list for node generation.

### 4.2.2: Defining the Model

To manage entropy, a Python dictionary is defined early on to specify the types of nodes that can be created in the database. This dictionary includes important information about each node type and guides functions on how to process data associated with these nodes.

The dictionary defines two _types_ of nodes (for now):
1. Objects
2. Operations

There are several nodes within each type, each with their own defined
1. Name
2. Unique Identifier (UID)
   - UID here refers to the _name of the column_ that is used for the unique identifier, not the value.
4. Functions
   - Tells the system what kind of role each node plays. Helps functions know what information to look for, what kind of nodes to create, and how to connect associated nodes.
   - The functions included in this database are:
     1. person
     2. item
     3. item_consuming
     4. item_acting
     5. item_creating
    -  May be a good idea to replace 'item' with 'object' and consolidate 'person' into 'object'.

### 4.2.3: Dynamic Generation of Cypher Scripts, Nodes, and Relationshps

Cypher scripts are dynamically generated by functions embedded inside of other functions that directly manipulate the database. There is a function for each of these different types queries:
1. gencypher_createConstraint
2. gencypher_createObjectNode
3. gencypher_createOperationNode
4. gencypher_createRelations

The script generates the database in the following order:

1. Create Node Constraints (using function db_setConstraints())
   - Scans node dictionary
   - Generates cypher script to create constraint for each node
   - Passes that script into the Neo4j database as a transaction
2. Create Object Nodes (using function db_pushObjects())
   - Reads the pandas data structures associated with Users and Ingredients
   - Generates cypher script to create object nodes
   - Passes that script into the Neo4j database as a transaction
3. Create Operation Nodes (using function db_pushOperations())
   - Iterates through the Operation_Log list
   - Generates cypher script to create operation nodes
   - Generates cypher scripts to connect operation nodes to relevant objects
   - Combines above cypher scripts
   - Passes final script into the Neo4j database as a transaction
   
## 4.3: Missing Features, Lessons Learned, and Recommended Next Steps
