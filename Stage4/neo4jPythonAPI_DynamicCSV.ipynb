{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neo4j Python API Practice (Generates Properties by Reading CSVs)\n",
    "### Overview:\n",
    "\n",
    "Teresa will write her own python code in Jupyter Notebook where...\n",
    "- She will read Version 2 CSVs from ~~the Neo4j dropbox folder~~ the [GitHub repository](https://github.com/lteresah/AMLS-GraphDatabase/).\n",
    "- She will create a ~~pandas dataframe~~ python list based on the data in the csv files\n",
    "- She will access a Neo4j database (local)\n",
    "- She will create nodes based on the information in the ~~pandas dataframe~~ python list\n",
    "- She will query the database (in parallel with checking Neo4j Bloom) to check her work.\n",
    "  \n",
    "### Motivation:\n",
    "- Establish python code that can be used in an automated pipeline.\n",
    "- Progress toward a \"touch-less\" graph database and data management system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the required packages, as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from neo4j import GraphDatabase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Access and Read the CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_csv = pd.read_csv(\"https://raw.githubusercontent.com/lteresah/AMLS-GraphDatabase/main/Stage2/CSVs_Version2/Neo4j_UsersF.csv\")\n",
    "otci_csv = pd.read_csv(\"https://raw.githubusercontent.com/lteresah/AMLS-GraphDatabase/main/Stage2/CSVs_Version2/Neo4j_OTC_Ingredients.csv\")\n",
    "mixpre_csv = pd.read_csv(\"https://raw.githubusercontent.com/lteresah/AMLS-GraphDatabase/main/Stage2/CSVs_Version2/Neo4j_op_MixMakePre.csv\")\n",
    "mixsamp_csv = pd.read_csv(\"https://raw.githubusercontent.com/lteresah/AMLS-GraphDatabase/main/Stage2/CSVs_Version2/Neo4j_op_MixMakeSamp.csv\")\n",
    "heat_csv = pd.read_csv(\"https://raw.githubusercontent.com/lteresah/AMLS-GraphDatabase/main/Stage2/CSVs_Version2/Neo4j_op_Heat.csv\")\n",
    "rest_csv = pd.read_csv(\"https://raw.githubusercontent.com/lteresah/AMLS-GraphDatabase/main/Stage2/CSVs_Version2/Neo4j_op_Rest.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create a ~~Pandas Structure~~ Python List based on the csvs of the OPERATION nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so advice from the internet says to **NEVER APPEND TO A PANDAS DATAFRAME** -- bad for memory and performance.\n",
    "\n",
    "Instead, grow a python LIST, and then convert to a pandas DataFrame *if necessary*... so I shall attempt that.\n",
    "\n",
    "Goal:\n",
    "1. Create a python LIST (with columns: Operation Type, Timestamp, User, Operation ID, Data)\n",
    "\n",
    "Steps:\n",
    "1. Create a *different block of code* *for each operation csv file* which extracts info for the first four columns\n",
    "2. Declare/Initiate a Python list with the first row filled in (column names)\n",
    "3. Takes the rest of the unused columns and creates the last Row (data)\n",
    "4. Append to the global python list.\n",
    "\n",
    "Note: This is *not* how things will be done in final practice... automated systems will be creating the python list in real time rather than reading from a csv.  Although annoying, I have to do this step to see if I can create a code which can read and write data with differing numbers and types of properties. And even if I did have to read from csvs, they would presumably be made in a structure does doesn't require writing a function specifically for that file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Python List (log) of Operations called operation_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for creating python lists from Operation Node Pandas files\n",
    "def make_operation_log(optype, csvfile, i = 0):\n",
    "    operation_log = []\n",
    "    for row in range(len(csvfile)):\n",
    "        Op_Type = optype\n",
    "        Timestamp = csvfile.loc[row].at[f\"{optype} Timestamp\"]\n",
    "        User = csvfile.loc[row].at[\"Executor\"]\n",
    "        Op_ID = csvfile.loc[row].at[f\"{optype} Operation ID\"]\n",
    "        Op_Data = {}\n",
    "        for column in csvfile.columns:\n",
    "            Op_Data[column] =  csvfile.loc[row].at[column]\n",
    "        operation_log.append([Op_Type, Timestamp, User, Op_ID, Op_Data])\n",
    "    return operation_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create all the python lists\n",
    "mixpre_log = make_operation_log('Mix', mixpre_csv)\n",
    "mixsamp_log = make_operation_log('Mix', mixsamp_csv)\n",
    "heat_log = make_operation_log('Heat', heat_csv)\n",
    "rest_log = make_operation_log('Rest', rest_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Declare the empty python list:\n",
    "# operation_log = [[\"Operation Type\", \"Timestamp\", \"User\", \"Operation ID\", \"Data\"]]\n",
    "# # Combine all the logs into one long python list\n",
    "# for entry in mixpre_log:\n",
    "#     operation_log.append(entry)\n",
    "# for entry in heat_log:\n",
    "#     operation_log.append(entry)\n",
    "# for entry in rest_log:\n",
    "#     operation_log.append(entry)\n",
    "# for entry in mixsamp_log:\n",
    "#     operation_log.append(entry)\n",
    "# for row in operation_log:\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the same as above without iterating (I THINK) and is therefore faster.  Maybe it's just the same...\n",
    "# Declare the empty python list:\n",
    "operation_log = [[\"Operation Type\", \"Timestamp\", \"User\", \"Operation ID\", \"Data\"]]\n",
    "unsorted_log = []\n",
    "# Combine all the logs into one long python list\n",
    "unsorted_log.extend(mixpre_log)\n",
    "unsorted_log.extend(heat_log)\n",
    "unsorted_log.extend(rest_log)\n",
    "unsorted_log.extend(mixsamp_log)\n",
    "sorted_log = sorted(unsorted_log,key = lambda x: x[1]) # sorting by timestamp to avoid conflicts when creating relationships\n",
    "operation_log.extend(sorted_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Connect to a database:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Run a local DATABASE\n",
    "\n",
    "Start your own local DBMS using the [Neo4j Desktop App](https://neo4j.com/download/?utm_source=Google&utm_medium=PaidSearch&utm_campaign=Evergreen&utm_content=AMS-Search-SEMBrand-Evergreen-None-SEM-SEM-NonABM&utm_term=download%20neo4j&utm_adgroup=download&gad_source=1&gclid=Cj0KCQjwpNuyBhCuARIsANJqL9Mfw2KSzysHnaaX0w_SPaPP49aDQPg5k6T-joWu_UnTcMYiWsrE4NEaAm4TEALw_wcB).\n",
    "\n",
    "The default Bolt Port that is used should be 7687, but you can change the code to match your settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish the DRIVER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URI examples: \"neo4j://localhost\", \"neo4j+s://xxx.databases.neo4j.io\"\n",
    "URI = \"neo4j://localhost:7687\" # Specify URI of already running database\n",
    "AUTH = (\"neo4j\",\"thisispractice\") # Enter username and password (this should probably be a reqeusted input in final product)\n",
    "\n",
    "with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "    driver.verify_connectivity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create the nodes and relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This cell will probably become part of a python module one day (once I learn how to do that)\n",
    "\n",
    "# Dictionary containing the allowed nodes in the DB, their UID row, and their functions.\n",
    "DB_Nodes = {'Objects':\n",
    "                [{'name': 'OTC Ingredient', 'UID': 'OTC ID', 'functions': ['item']},\n",
    "                {'name': 'User', 'UID': 'kerberos','functions': ['person']},\n",
    "                {'name': 'Precursor', 'UID': 'Precursor ID' , 'functions': ['item']},\n",
    "                {'name': 'Sample', 'UID': 'Sample ID', 'functions': ['item']}], \n",
    "            'Operations':\n",
    "                [{'name': 'Mix', 'UID': 'Mix Operation ID', 'functions': ['item_consuming','item_creating']},\n",
    "                {'name': 'Heat', 'UID': 'Heat Operation ID','functions': ['item_acting']},\n",
    "                {'name': 'Rest', 'UID': 'Rest Operation ID', 'functions': ['item_acting']}]\n",
    "            }\n",
    "\n",
    "# Function to get name of uid column given the node name\n",
    "def get_uidname(nodename, DB_Nodes = DB_Nodes):\n",
    "    found = False\n",
    "    for object in DB_Nodes['Objects']:\n",
    "        if object['name'] == nodename:\n",
    "            uid = object['UID']\n",
    "            found = True\n",
    "            return uid  \n",
    "    for operation in DB_Nodes['Operations']:\n",
    "        if operation['name'] == nodename:\n",
    "            uid = operation['UID']\n",
    "            found = True\n",
    "            return uid\n",
    "    if not found:\n",
    "        print(f\"{nodename} is not registered as a Node in the DataBase.\")\n",
    "        return NameError\n",
    "    \n",
    "# Function that creates constraints based on current dictionary of allowed nodes.\n",
    "\n",
    "# Function to get functions of node given the node name\n",
    "def get_functions(nodename, DB_Nodes = DB_Nodes):\n",
    "     found = False\n",
    "     for object in DB_Nodes['Objects']:\n",
    "        if object['name'] == nodename:\n",
    "            functions = object['functions']\n",
    "            found = True\n",
    "            return functions\n",
    "     for operation in DB_Nodes['Operations']:\n",
    "        if operation['name'] == nodename:\n",
    "            functions = operation['functions']\n",
    "            found = True\n",
    "            return functions\n",
    "     if not found:\n",
    "        print(f\"{nodename} is not registered as a Node in the DataBase.\")\n",
    "        return NameError\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This cell will probably become part of a python module one day (once I learn how to do that)\n",
    "\n",
    "# Function that generates cypher code for creating CONSTRAINTS based on the nodename\n",
    "def gencypher_createConstraint(nodename):\n",
    "    for object in DB_Nodes['Objects']:\n",
    "        if object['name'] == nodename:\n",
    "            uid = get_uidname(nodename)\n",
    "            cypher_string = (f\"\"\"\n",
    "                             CREATE CONSTRAINT `{uid} {nodename}_uniq` IF NOT EXISTS\n",
    "                             FOR (n: `{nodename}`) // is full label for this type of node\n",
    "                             REQUIRE (n.`{uid}`) IS UNIQUE\n",
    "                             \"\"\")\n",
    "    for operation in DB_Nodes['Operations']:\n",
    "        if operation['name'] == nodename:\n",
    "            uid = get_uidname(nodename)\n",
    "            cypher_string = (f\"\"\"\n",
    "                             CREATE CONSTRAINT `{uid} {nodename}_uniq` IF NOT EXISTS\n",
    "                             FOR (n: `{nodename}`) // is full label for this type of node\n",
    "                             REQUIRE (n.`{uid}`) IS UNIQUE\n",
    "                             \"\"\")\n",
    "    return cypher_string\n",
    "            \n",
    "\n",
    "# Function that generates the cypher code for OBJECT node creation, given a pandas DataFrame\n",
    "def gencypher_createObjectNode(nodename, csvfile):\n",
    "    uid = get_uidname(nodename)\n",
    "    cypher_string = (\"MERGE (n: \" + f\"`{nodename}`\" + \"{\" +  f\"`{uid}` : $`{uid}`\" \"})\") # replace this with something more dynamic in future\n",
    "    for property in csvfile.columns:\n",
    "        next_string = f\"\\nSET n.`{property}` = $`{property}`\" #Probably not good to do security wise... Injection risk\n",
    "        cypher_string = (cypher_string + next_string)\n",
    "    return cypher_string\n",
    "\n",
    "# Function that generates the cypher code for OPERATION node creation, given a row in the python list\n",
    "def gencypher_createOperationNode(row):\n",
    "    nodename = row[0]\n",
    "    uid = get_uidname(nodename)\n",
    "    data = row[4]\n",
    "    cypher_string = (f\"MERGE (n:Operation:`{nodename}`\" + \"{\" + f\"`{uid}` : \" + f\"$`{uid}`\" + \"})\")\n",
    "    for key in data.keys():\n",
    "        next_string = f\"\\nSET n.`{key}` = $`{key}`\" #Probably not good to do security wise... Injection risk\n",
    "        cypher_string = (cypher_string + next_string)\n",
    "    params = {}\n",
    "    params = data\n",
    "    return (cypher_string, params)\n",
    "\n",
    "# Function that generates the cypher code for RELATIONS going to/from OPERATION node, given a row in the python list (operation_log)\n",
    "def gencypher_createRelations(row):\n",
    "    nodename = row[0]\n",
    "    uid = get_uidname(nodename)\n",
    "    functions = get_functions(nodename)\n",
    "    data = row[4]\n",
    "    item_consuming = False\n",
    "    item_creating = False\n",
    "    item_acting = False\n",
    "    if 'item_consuming' in functions:\n",
    "        item_consuming = True\n",
    "        ing_types = [value for key, value in data.items() if 'Ing' in key and 'Type' in key]\n",
    "        ing_IDs = [value for key, value in data.items() if 'Ing' in key and 'ID' in key]\n",
    "    if 'item_creating' in functions:\n",
    "        item_creating = True\n",
    "        created_types = [value for key, value in data.items() if 'New Object Type' in key]\n",
    "        created_IDs = [value for key, value in data.items() if 'New Object ID' in key]\n",
    "        #created_description = [value for key, value in data.items() if 'New Object Description' in key]\n",
    "    if 'item_acting' in functions:\n",
    "        item_acting = True\n",
    "        acted_types = [value for key, value in data.items() if 'Object Type' in key]\n",
    "        acted_IDs = [value for key, value in data.items() if 'Object ID' in key]\n",
    "    # Create Relationships GOING TO node\n",
    "    cypher_string = (f\"MATCH (target: Operation:`{nodename}`\" + \" { \" + f\"`{uid}`: $`{uid}`\" + \" })\")\n",
    "    # Connecting to Executor\n",
    "    user_string = (\"\"\"MATCH (user: `User` { `kerberos` : $`Executor` })\n",
    "                   MERGE (user) -[:EXECUTED]-> (target)\"\"\")\n",
    "    cypher_string = (cypher_string + user_string)\n",
    "    # Connecting to Ingredients\n",
    "    if item_consuming:\n",
    "        print(\"\\tConnecting to Ingredients\")\n",
    "        for i in range(len(ing_IDs)):\n",
    "            ing_uid = get_uidname(ing_types[i])\n",
    "            begin_string = (\"\\nWITH target\")\n",
    "            cypher_string = (cypher_string + begin_string)\n",
    "            match_ing_string = (f\"\\nMATCH (Ing{i+1}: `{ing_types[i]}` \" +  \"{ \" + f\"`{ing_uid}` : $`Ing {i+1} ID`\"  +   \" })\")\n",
    "            cypher_string = (cypher_string + match_ing_string)\n",
    "            make_rel_string = f\"\\nMERGE (Ing{i+1}) -[: `WENT_TO`]-> (target)\"\n",
    "            cypher_string = (cypher_string + make_rel_string)\n",
    "    # Connecting to Created Objects\n",
    "    if item_creating:\n",
    "        print(\"\\tCreating/Connecting to Creations\")\n",
    "        for i in range(len(created_IDs)):\n",
    "            created_uid = get_uidname(created_types[i])\n",
    "            begin_string = (\"\\nWITH target\")\n",
    "            cypher_string = (cypher_string + begin_string)\n",
    "            makeproduct_string = (f\"\\nMERGE (Created{i+1}: `{created_types[i]}` \" +  \"{ \" + f\"`{created_uid}` : $`New Object ID`\"  +   \" })\")\n",
    "            cypher_string = (cypher_string + makeproduct_string)\n",
    "            make_rel_string = f\"\\nMERGE (Created{i+1}) <-[: `CREATED`]- (target)\"\n",
    "            cypher_string = (cypher_string + make_rel_string)\n",
    "    # Connecting to Acted Objects\n",
    "    if item_acting:\n",
    "        print(\"\\tConnecting to acted Object(s)\")\n",
    "        for i in range(len(acted_IDs)):\n",
    "            acted_uid = get_uidname(acted_types[i])\n",
    "            pass_string = (\"\\nWITH target\")\n",
    "            cypher_string = (cypher_string + pass_string)\n",
    "            match_object_string = (f\"\\nMATCH (Acted{i+1}: `{acted_types[i]}` \" +  \"{ \" + f\"`{acted_uid}` : $`{nodename} Object ID`\"  +   \" })\")\n",
    "            cypher_string = (cypher_string + match_object_string)\n",
    "            make_rel_string = f\"\\nMERGE (Acted{i+1}) -[: `WENT_TO`]-> (target)\"\n",
    "            cypher_string = (cypher_string + make_rel_string)\n",
    "            # For item acting, updates the event stream tracking relationship -[:THEN]-> after creating the [:WENT_TO] relationship\n",
    "            # This is really really hard to do for timestamps that have different names.  Lesson learned.\n",
    "            add_eventstream_string = (f\"\"\"\\n\n",
    "                                        WITH Acted{i+1}\n",
    "                                        MATCH (Acted{i+1})-[r:WENT_TO]->(op:Operation)\n",
    "                                        WITH Acted{i+1}, op, properties(op) as properties, [key in keys(op) where key contains 'Timestamp'] as timestamp\n",
    "                                        WITH Acted{i+1}, op ORDER BY properties[timestamp[0]]\n",
    "                                        WITH Acted{i+1}, collect(op) as Operations\n",
    "                                        FOREACH (j IN RANGE(0,size(Operations)-2)|\n",
    "                                            FOREACH (before in [Operations[j]]|\n",
    "                                                FOREACH(after in [Operations[j+1]]|\n",
    "                                                    MERGE (before)-[:THEN]->(after))))\"\"\")\n",
    "        cypher_string = (cypher_string + add_eventstream_string)\n",
    "    # Setting the paramaters        \n",
    "    params = {}\n",
    "    params = data\n",
    "    return (cypher_string, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goes through dictionary of nodes in the DB and creates constraints for each node\n",
    "def db_setConstraints(DB_Nodes = DB_Nodes):\n",
    "    with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "        with driver.session(database=\"neo4j\") as session:\n",
    "            for object in DB_Nodes['Objects']:\n",
    "                nodename = object['name']\n",
    "                cypherstring_constraint = gencypher_createConstraint(nodename)\n",
    "                session.run(cypherstring_constraint)\n",
    "            for operation in DB_Nodes['Operations']:\n",
    "                nodename = operation['name']\n",
    "                cypherstring_constraint = gencypher_createConstraint(nodename)\n",
    "                session.run(cypherstring_constraint)\n",
    "\n",
    "\n",
    "# Function that reads csv file for OBJECT type nodes and then creates the nodes\n",
    "def db_pushObjects(nodename, csvfile):\n",
    "    with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "        with driver.session(database=\"neo4j\") as session:\n",
    "            cypherstring_nodes = gencypher_createObjectNode(nodename, csvfile)\n",
    "            csv_dict = csvfile.to_dict(orient = 'records') #changing the pd dataframe to a dict for iteration through rows.\n",
    "            for row in csv_dict:\n",
    "                params = {}\n",
    "                params = row\n",
    "                session.run(cypherstring_nodes, params)\n",
    "\n",
    "\n",
    "# Function that creates OPERATION nodes+relationships based on the entries in the operation_log (python list)\n",
    "def db_pushOperations(operation_log, count = 0):\n",
    "    with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "        with driver.session(database=\"neo4j\") as session:\n",
    "            for entry in operation_log[1:]: # Iterate over log entries -- skip the first row which is just column names.\n",
    "               print(f\"Pushing entry[{count}] to DB for operation type: {entry[0]}:\")\n",
    "               cyphernode_string, cyphernode_params = gencypher_createOperationNode(entry)\n",
    "               session.run(cyphernode_string, cyphernode_params)\n",
    "               print(f\"\\tCompleted node creation\")\n",
    "               cypherrel_string, cypherrel_params = gencypher_createRelations(entry)\n",
    "               session.run(cypherrel_string, cypherrel_params)\n",
    "               print(f\"\\tCompleted connections\")\n",
    "               count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Constraints\n",
    "db_setConstraints()\n",
    "# Push Objects\n",
    "db_pushObjects('User', user_csv)\n",
    "db_pushObjects('OTC Ingredient', otci_csv)\n",
    "# Push Operations\n",
    "db_pushOperations(operation_log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Neo4jEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
